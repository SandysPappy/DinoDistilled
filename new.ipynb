{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8bfb9d-048a-47ed-bdeb-be4f08ef2034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp\n",
      "From (redirected): https://drive.google.com/uc?id=137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp&confirm=t&uuid=0e0bca9c-651b-44d5-aa2e-23d49ab9dd68\n",
      "To: /storage/usersb/CoE_Shraddha/DinoDistilled/101_ObjectCategories.tar.gz\n",
      "100%|███████████████████████████████████████| 132M/132M [00:01<00:00, 71.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted successfully.\n",
      "Training set size: 6943\n",
      "Validation set size: 867\n",
      "Test set size: 867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/users/CoE_Shraddha/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683a39da9c0e4813b5a705728845d639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing embeddings:   0%|          | 0/217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eac9692f60d49508e9781c38f1f405d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing embeddings:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9109e9c78d7f40de8c805f3af774e6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing embeddings:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49148dd57ae14494bce335b35a7a7662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10, Training:   0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.5042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1972fecbc2d2476d92d12bf24924c67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10, Validating:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Validation Loss: 0.1233, Validation Accuracy: 95.95%\n",
      "Best model saved to teacher_model/best_model_epoch_1.pth with Validation Loss: 0.1233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875cf95fef3d401fa035be57218939e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10, Training:   0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.0661\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ce524321204a0f9ec76dc19071b05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10, Validating:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Validation Loss: 0.0905, Validation Accuracy: 96.30%\n",
      "Best model saved to teacher_model/best_model_epoch_2.pth with Validation Loss: 0.0905\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b3f841d16e44d7a1b6d3a94bce7e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10, Training:   0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.0458\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6b6ed08c1441ebbe17e5c7eb1a8707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10, Validating:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Validation Loss: 0.0972, Validation Accuracy: 96.30%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef5c11e233e4ffbb701e689dde5cad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10, Training:   0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.0371\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f85437d7fcf4c3da52f7a1137b39972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10, Validating:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Validation Loss: 0.0918, Validation Accuracy: 96.64%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2b02306ff24f31887170fc43b639cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10, Training:   0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.0326\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8db435b8384fdb97501bbd1e3cd73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10, Validating:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Validation Loss: 0.0917, Validation Accuracy: 96.76%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a272722c0cbf43cd9ef58fe38c0be0c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10, Training:   0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc64e5776ada4dbcb668b2c5bb419ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10, Validating:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Validation Loss: 0.0928, Validation Accuracy: 96.76%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f570ce801d946539cff3041311c05f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10, Training:   0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36f47a32228452ea1eccac265a511ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10, Validating:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Validation Loss: 0.0970, Validation Accuracy: 97.11%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b3bcdba04e495ea0f27b41fbd80c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10, Training:   0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0236\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac7805210c24d8faf550a05a2b4d02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10, Validating:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Validation Loss: 0.1028, Validation Accuracy: 96.88%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34329bc0d68146169233c81c0fd6fd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10, Training:   0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32b38de3f09421fb1b89db0b63f361a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10, Validating:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Validation Loss: 0.0971, Validation Accuracy: 97.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2d05252fb64ba0b99c628ed7a0628c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10, Training:   0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b3592f40564c50ac39af079ba7ee31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10, Validating:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Validation Loss: 0.1006, Validation Accuracy: 97.22%\n",
      "Test Accuracy: 96.19%\n",
      "-----------------Starting KD--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8a0867a56d4f8289b0f6a9fc158be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1/15:   0%|          | 0/217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.7827, Validation Loss: 0.5526\n",
      "New best model saved at epoch 1 with Validation Loss: 0.5526\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960fd74483a84d00bb08bb4cb8318023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2/15:   0%|          | 0/217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 0.5734, Validation Loss: 0.4300\n",
      "New best model saved at epoch 2 with Validation Loss: 0.4300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ed3e9ab27d46828c571c7aeb4e2dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3/15:   0%|          | 0/217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 0.4879, Validation Loss: 0.3661\n",
      "New best model saved at epoch 3 with Validation Loss: 0.3661\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cd0cc637e2460cb46d05ac66d74265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4/15:   0%|          | 0/217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 0.4366, Validation Loss: 0.3241\n",
      "New best model saved at epoch 4 with Validation Loss: 0.3241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b313aea42a4150a6dd0e8e7b7bcf37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 5/15:   0%|          | 0/217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 0.4018, Validation Loss: 0.2992\n",
      "New best model saved at epoch 5 with Validation Loss: 0.2992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955e08614a15401caa129b13d9580436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 6/15:   0%|          | 0/217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 0.3761, Validation Loss: 0.2794\n",
      "New best model saved at epoch 6 with Validation Loss: 0.2794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fe8d3c327b487480f154c5e35c6c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 7/15:   0%|          | 0/217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import torch.hub\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pathlib import Path\n",
    "import os\n",
    "import gdown\n",
    "import tarfile\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "# Download the dataset\n",
    "url = 'https://drive.google.com/uc?id=137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp'\n",
    "output = '101_ObjectCategories.tar.gz'\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "# Extract the dataset\n",
    "if tarfile.is_tarfile(output):\n",
    "    with tarfile.open(output, \"r:gz\") as tar_ref:\n",
    "        tar_ref.extractall()\n",
    "    print(\"File extracted successfully.\")\n",
    "else:\n",
    "    print(\"Downloaded file is not a tar file.\")\n",
    "\n",
    "\n",
    "transform_image = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(256),       \n",
    "    transforms.CenterCrop(224),  \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),  \n",
    "])\n",
    "\n",
    "dataset_path = './101_ObjectCategories'\n",
    "original_dataset = datasets.ImageFolder(dataset_path)\n",
    "filtered_data = [(img, label) for img, label in original_dataset.imgs if \"BACKGROUND_Google\" not in img]\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.data[index]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label - int(label > original_dataset.class_to_idx['BACKGROUND_Google'])\n",
    "\n",
    "\n",
    "filtered_dataset = CustomDataset(filtered_data, transform=transform_image)\n",
    "\n",
    "\n",
    "total_size = len(filtered_dataset)\n",
    "val_size = test_size = int(0.1 * total_size)  \n",
    "train_size = total_size - val_size - test_size  \n",
    "\n",
    "# Split\n",
    "train_dataset, test_val_dataset = random_split(filtered_dataset, [train_size, val_size + test_size])\n",
    "val_dataset, test_dataset = random_split(test_val_dataset, [val_size, test_size])\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")\n",
    "\n",
    "# DinoV2\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "dinov2_vits14 = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vits14\").to(device)\n",
    "\n",
    "# Embeddings\n",
    "def compute_embeddings(data_loader):\n",
    "    dinov2_vits14.eval()\n",
    "    all_embeddings = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(data_loader, desc=\"Computing embeddings\"):\n",
    "            images = images.to(device)\n",
    "            embeddings = dinov2_vits14(images)\n",
    "            all_embeddings.append(embeddings.cpu().numpy())\n",
    "            labels.extend(targets.numpy())\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    return all_embeddings, labels\n",
    "train_embeddings, train_labels = compute_embeddings(train_loader)\n",
    "val_embeddings, val_labels = compute_embeddings(val_loader)\n",
    "test_embeddings, test_labels = compute_embeddings(test_loader)\n",
    "\n",
    "# Classifier\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(EmbeddingClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "input_size = 384  # Feature dimension of DINOv2 embeddings\n",
    "hidden_size = 512 \n",
    "num_classes = 101\n",
    "\n",
    "classifier = EmbeddingClassifier(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "train_embeddings_tensor = torch.tensor(train_embeddings).float().to(device)\n",
    "train_labels_tensor = torch.tensor(train_labels).long().to(device)\n",
    "\n",
    "val_embeddings_tensor = torch.tensor(val_embeddings).float().to(device)\n",
    "val_labels_tensor = torch.tensor(val_labels).long().to(device)\n",
    "\n",
    "model_dir = Path('teacher_model')\n",
    "model_dir.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "num_train_batches = len(train_embeddings_tensor) // batch_size\n",
    "num_val_batches = len(val_embeddings_tensor) // batch_size\n",
    "\n",
    "best_val_loss = float('inf') \n",
    "\n",
    "# Train\n",
    "for epoch in range(epochs):\n",
    "    classifier.train()\n",
    "    train_loss = 0.0\n",
    "    for i in tqdm(range(num_train_batches), desc=f'Epoch {epoch+1}/{epochs}, Training'):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i + 1) * batch_size\n",
    "        \n",
    "        images = train_embeddings_tensor[batch_start:batch_end]\n",
    "        labels = train_labels_tensor[batch_start:batch_end]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = classifier(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = train_loss / num_train_batches\n",
    "    tqdm.write(f'Epoch [{epoch+1}/{epochs}], Training Loss: {avg_train_loss:.4f}')\n",
    "    \n",
    "    # Validation phase\n",
    "    classifier.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(num_val_batches), desc=f'Epoch {epoch+1}/{epochs}, Validating'):\n",
    "            batch_start = i * batch_size\n",
    "            batch_end = (i + 1) * batch_size\n",
    "            \n",
    "            images = val_embeddings_tensor[batch_start:batch_end]\n",
    "            labels = val_labels_tensor[batch_start:batch_end]\n",
    "            \n",
    "            outputs = classifier(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / num_val_batches\n",
    "    val_accuracy = correct / total * 100\n",
    "    tqdm.write(f'Epoch [{epoch+1}/{epochs}], Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    # Save\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model_path = model_dir / f'best_model_epoch_{epoch+1}.pth'\n",
    "        torch.save(classifier.state_dict(), best_model_path)\n",
    "        tqdm.write(f\"Best model saved to {best_model_path} with Validation Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Test\n",
    "test_embeddings_tensor = torch.tensor(test_embeddings).float().to(device)\n",
    "test_labels_tensor = torch.tensor(test_labels).long().to(device)\n",
    "\n",
    "classifier.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = classifier(test_embeddings_tensor)  # Forward pass\n",
    "    _, predicted = torch.max(outputs, 1)  \n",
    "    total = test_labels_tensor.size(0) \n",
    "    correct = (predicted == test_labels_tensor).sum().item()  \n",
    "\n",
    "# Accuracy\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "\n",
    "print(\"-----------------Starting KD--------------------\")\n",
    "\n",
    "\n",
    "class CosineSimilarityLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cosine_similarity = nn.CosineSimilarity()\n",
    "\n",
    "    def forward(self, student_outputs, teacher_outputs):\n",
    "        loss = 1 - self.cosine_similarity(student_outputs, teacher_outputs).mean()\n",
    "        return loss\n",
    "\n",
    "\n",
    "# KD DinoV2 -> EfficientNetV2\n",
    "# class EfficientNetV2Embeddings(nn.Module):\n",
    "#     def __init__(self, output_dim=384):\n",
    "#         super(EfficientNetV2Embeddings, self).__init__()\n",
    "#         self.base_model = timm.create_model('efficientnetv2_rw_s', pretrained=True, features_only=True)\n",
    "#         feature_dim = self.base_model.feature_info[-1]['num_chs']\n",
    "    \n",
    "#         self.embedding_layer = nn.Linear(feature_dim, output_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         features = self.base_model(x)[-1] \n",
    "#         pooled_features = features.mean([2, 3])\n",
    "#         embeddings = self.embedding_layer(pooled_features)\n",
    "#         return embeddings\n",
    "\n",
    "class EfficientNetV2Embeddings(nn.Module):\n",
    "    def __init__(self, output_dim=384, dropout_rate=0.5):\n",
    "        super(EfficientNetV2Embeddings, self).__init__()\n",
    "        self.base_model = timm.create_model('efficientnetv2_rw_s', pretrained=True, features_only=True)\n",
    "        feature_dim = self.base_model.feature_info[-1]['num_chs']\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.embedding_layer = nn.Linear(feature_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.base_model(x)[-1]\n",
    "        pooled_features = features.mean([2, 3])\n",
    "        norm_features = self.batch_norm(pooled_features)\n",
    "        dropped_out_features = self.dropout(norm_features)\n",
    "        embeddings = self.embedding_layer(dropped_out_features)\n",
    "        return embeddings\n",
    "        \n",
    "teacher_model = dinov2_vits14\n",
    "student_model = EfficientNetV2Embeddings(output_dim=384)\n",
    "student_model.to(device)\n",
    "\n",
    "def validate(model, criterion, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _ in data_loader:\n",
    "            images = images.to(device)\n",
    "        \n",
    "            teacher_embeddings = teacher_model(images)\n",
    "\n",
    "            student_embeddings = model(images)\n",
    "            loss = criterion(student_embeddings, teacher_embeddings)\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            total_samples += images.size(0)\n",
    "    avg_loss = total_loss / total_samples\n",
    "    return avg_loss\n",
    "\n",
    "model_save_dir = Path('distilled_effv2')\n",
    "model_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "criterion = CosineSimilarityLoss()\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "epochs = 15\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    student_model.train()\n",
    "    total_train_loss = 0.0\n",
    "    \n",
    "    for images, _ in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{epochs}\"):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            teacher_embeddings = teacher_model(images)\n",
    "        \n",
    "        student_embeddings = student_model(images)\n",
    "        \n",
    "        loss = criterion(student_embeddings, teacher_embeddings)\n",
    "        total_train_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_losses.append(total_train_loss / len(train_loader))\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "    \n",
    "    avg_val_loss = validate(student_model, criterion, val_loader, device)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "    \n",
    "    # Check if the current model is better than the best model so far\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_epoch = epoch + 1\n",
    "        best_model_path = model_save_dir / f'best_model_epoch_{best_epoch}.pth'\n",
    "        \n",
    "        torch.save(student_model.state_dict(), best_model_path)\n",
    "        print(f\"New best model saved at epoch {best_epoch} with Validation Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "print(f\"Best model was saved at epoch {best_epoch} with Validation Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Plotting the training and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss during Knowledge Distillation')\n",
    "plt.legend()\n",
    "plt.savefig(plot_dir / 'kd_training_validation_losses.jpg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "\n",
    "best_model_path = model_save_dir / f'best_model_epoch_{best_epoch}.pth'\n",
    "student_model = EfficientNetV2Embeddings(output_dim=384).to(device)\n",
    "student_model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "print(\"Best model loaded.\")\n",
    "\n",
    "# def evaluate_model(model, teacher_model, criterion, data_loader, device):\n",
    "#     model.eval() \n",
    "#     teacher_model.eval()\n",
    "#     total_loss = 0.0\n",
    "#     total_cosine_similarity = 0.0\n",
    "#     total_samples = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for images, _ in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "#             images = images.to(device)\n",
    "#             student_embeddings = model(images)\n",
    "#             teacher_embeddings = teacher_model(images)\n",
    "#             loss = criterion(student_embeddings, teacher_embeddings)\n",
    "#             total_loss += loss.item() * images.size(0)\n",
    "#             cosine_similarity = nn.functional.cosine_similarity(student_embeddings, teacher_embeddings, dim=1).mean()\n",
    "#             total_cosine_similarity += cosine_similarity.item() * images.size(0)\n",
    "#             total_samples += images.size(0)\n",
    "    \n",
    "#     avg_loss = total_loss / total_samples\n",
    "#     avg_cosine_similarity = total_cosine_similarity / total_samples\n",
    "\n",
    "#     print(f\"Test MSE Loss: {avg_loss:.4f}\")\n",
    "#     print(f\"Average Cosine Similarity: {avg_cosine_similarity:.4f}\")\n",
    "\n",
    "# evaluate_model(student_model, teacher_model, criterion, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8e856-201a-49c4-92cb-a129a2cfb09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = Path('plots_new')\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save directory for models\n",
    "model_save_dir = Path('distilled_effv2_new')\n",
    "model_save_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac85a2-ae99-4d39-8a33-290277bbc201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingClassifierV2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(EmbeddingClassifierV2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def compute_embeddings(model, loader):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader, desc=\"Computing embeddings\"):\n",
    "            images = images.to(device)\n",
    "            emb = model(images)\n",
    "            embeddings.append(emb.cpu().numpy())\n",
    "            labels.extend(targets.cpu().numpy())\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    labels = np.array(labels)\n",
    "    return embeddings, labels\n",
    "\n",
    "# Compute embeddings using the distilled student model\n",
    "train_embeddings, train_labels = compute_embeddings(student_model, train_loader)\n",
    "val_embeddings, val_labels = compute_embeddings(student_model, val_loader)\n",
    "test_embeddings, test_labels = compute_embeddings(student_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68034cba-2f89-4bfa-a4f5-7db9b98ace39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_classifier(train_embeddings, train_labels, val_embeddings, val_labels, test_embeddings, test_labels, num_classes):\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_embeddings), torch.tensor(train_labels))\n",
    "    val_dataset = torch.utils.data.TensorDataset(torch.tensor(val_embeddings), torch.tensor(val_labels))\n",
    "    test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_embeddings), torch.tensor(test_labels))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = EmbeddingClassifierV2(train_embeddings.shape[1], 512, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(10):  # Train for 10 epochs\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for data in train_loader:\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                inputs, targets = data\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_embedding_classifier_v2.pth')\n",
    "\n",
    "    # Testing the model\n",
    "    model.load_state_dict(torch.load('best_embedding_classifier_v2.pth'))\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "    test_accuracy = correct / total * 100\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Call the function with proper arguments\n",
    "train_and_evaluate_classifier(train_embeddings, train_labels, val_embeddings, val_labels, test_embeddings, test_labels, num_classes=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369cf2f-9156-43e4-92a7-bd0ed00d4bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "# After training and validation in your training function\n",
    "save_model(model, 'distilled_effnetV2_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1251498-ad3a-4c0b-b748-636e15c3a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_classifier(train_embeddings, train_labels, val_embeddings, val_labels, test_embeddings, test_labels, num_classes, device):\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_embeddings), torch.tensor(train_labels))\n",
    "    val_dataset = torch.utils.data.TensorDataset(torch.tensor(val_embeddings), torch.tensor(val_labels))\n",
    "    test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_embeddings), torch.tensor(test_labels))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = EmbeddingClassifierV2(train_embeddings.shape[1], 512, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(10):  # Train for 10 epochs\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for data in train_loader:\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                inputs, targets = data\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_embedding_classifier_v2.pth')\n",
    "\n",
    "    # Testing the model\n",
    "    model.load_state_dict(torch.load('best_embedding_classifier_v2.pth'))\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    test_accuracy = correct / total * 100\n",
    "    precision = precision_score(true_labels, predictions, average='macro')\n",
    "    recall = recall_score(true_labels, predictions, average='macro')\n",
    "    f1 = f1_score(true_labels, predictions, average='macro')\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Example call to the function, ensure to pass `device`\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_and_evaluate_classifier(train_embeddings, train_labels, val_embeddings, val_labels, test_embeddings, test_labels, num_classes=101, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f84a8-c61e-4ab3-8d6f-764d949514c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
